
# Instalamos los paquetes de Python necesarios

!pip install langchain_community 
!pip install replicate 

# Configuramos el entorno importando las bibliotecas necesarias, extrayendo el token de 
API, configurándolo como una variable de entorno, definiendo el modelo y creando una 
instancia del modelo Replicate. 

from langchain_community.llms import Replicate 
import os 
from google.colab import userdata
 
# Establecemos el token de API 
api_token = userdata.get('api_token') 
os.environ["REPLICATE_API_TOKEN"] = api_token 

# Configuración del modelo 
model = "ibm-granite/granite-3.0-8b-instruct" 

output = Replicate( 
model=model, replicate_api_token=api_token,)

# Ingresamos muestras de reseñas de clientes para probar el modelo.
# Definimos las reseñas de los clientes  
customer_reviews = [  
"La batería dura todo el día, pero el teléfono se calienta 
mientras juego",  
"La pantalla es demasiado oscura en exteriores, pero me encantan 
los colores en interiores",  
"Este teléfono es rápido, pero falla cuando abro 
ciertas aplicaciones".  
]  

# Refinamos la solicitud para incluir reseñas  
reviews_text = "\n".join([f"Review {i+1}: {review}" for i, review in enumerate(customer_reviews)])

# Establecemos los parámetros del modelo para la formulación de la solicitud con valores predeterminados  
# parameters = {  
    # "top_k": 0,  
    # "top_p": 1.0,  
    # "max_tokens": 256,   
    # "min_tokens": 0,  
    # "random_seed": None,  
    # "repetition_penalty": 1,0,  
    # "stopping_criteria": "length (256 tokens)",  
    # "stopping_sequence": None  
} 

# Agregamos la solicitud inicial 
# refined_prompt = f""":  
# Clasifica estas reseñas como positivas, negativas o mixtas y etiqueta los aspectos prioritarios pertinentes, como la duración de la batería, la calidad de la pantalla o el rendimiento  

# {reviews_text}  
# """  

# Invocamos el modelo  
# response = output.invoke(refined_prompt, parameters=parameters) 
 
# Imprimimos la respuesta  
# print("Granite Model Refined Response:\n")  

# print(response)

# Actualizamos el parámetro top_k configurándolo en 5 para agregar granularidades al categorizar explícitamente cada sentimiento de una reseña. 
# Refinamos el valor del parámetro top_k del modelo 
parameters = {  
    "top_k": 5,  
    "top_p": 1.0,  
    "max_tokens": 256,  
    "min_tokens": 0,  
    "random_seed": None,  
    "repetition_penalty": 1,0,  
    "stopping_criteria": "length (256 tokens)",  
    "stopping_sequence": None  
}

# Agregamos la solicitud inicial 
refined_prompt = f""":  
Clasifica estas reseñas como positivas, negativas o mixtas y 
etiqueta los aspectos prioritarios pertinentes, como la duración de 
la batería, la calidad de la pantalla o el rendimiento  

{reviews_text}  
"""  

# Invocamos el modelo  
response = output.invoke(refined_prompt, parameters=parameters) 
 
# Imprimimos la respuesta  
print("Granite Model Refined Response:\n")  

print(response)
